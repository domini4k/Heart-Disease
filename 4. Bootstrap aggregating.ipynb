{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Bootstrap aggregating"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Using ensemble methods can greatly improve the results achieved with weak machine learning algorithms. Ensemble methods achieve better performance by \"adding\" the results of many statistically independent models."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn import datasets ## Get dataset from sklearn\nimport sklearn.model_selection as ms\nimport sklearn.metrics as sklm\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport numpy.random as nr\n\n%matplotlib inline",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Features = np.array(pd.read_csv('Features.csv'))\nLabels = np.array(pd.read_csv('Labels.csv'))\nLabels = Labels.reshape(Labels.shape[0],)\nprint(Features.shape)\nprint(Labels.shape)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(297, 29)\n(297,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nr.seed(123)\ninside = ms.KFold(n_splits=10, shuffle = True)\nnr.seed(321)\noutside = ms.KFold(n_splits=10, shuffle = True)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Define the dictionary for the grid search and the model object to search on\nparam_grid = {\"max_features\": [2, 3, 5, 10, 15], \"min_samples_leaf\":[3, 5, 10, 20]}\n## Define the random forest model\nnr.seed(3456)\nrf_clf = RandomForestClassifier(class_weight = {0:0.85, 1:0.15}, n_estimators = 100) \n\n## Perform the grid search over the parameters\nnr.seed(4455)\nrf_clf = ms.GridSearchCV(estimator = rf_clf, param_grid = param_grid, \n\n                      cv = inside, # Use the inside folds\n                      scoring = 'roc_auc',\n                      return_train_score = True)\nrf_clf.fit(Features, Labels)\nprint(rf_clf.best_estimator_.max_features)\nprint(rf_clf.best_estimator_.min_samples_leaf)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "2\n3\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This nested cross - validation searches for best parameters. Max_features is pretty obvious. Too many features can overfit a model which was shown in the previous notebook. Min_samples_leaf stands for choosing the best parameter for tree leaves. Too few samples will cause overfitting, too many will cause bias."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nr.seed(498)\ncv_estimate = ms.cross_val_score(rf_clf, Features, Labels,\n                                 cv = outside) # Use the outside folds\n\nprint('Mean performance metric = %4.3f' % np.mean(cv_estimate))\nprint('SDT of the metric       = %4.3f' % np.std(cv_estimate))\nprint('Outcomes by cv fold')\nfor i, x in enumerate(cv_estimate):\n    print('Fold %2d    %4.3f' % (i+1, x))",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Mean performance metric = 0.907\nSDT of the metric       = 0.050\nOutcomes by cv fold\nFold  1    0.906\nFold  2    0.869\nFold  3    0.896\nFold  4    0.871\nFold  5    0.866\nFold  6    0.828\nFold  7    0.968\nFold  8    0.957\nFold  9    0.995\nFold 10    0.917\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Randomly sample cases to create independent training and test data\nnr.seed(1115)\nindx = range(Features.shape[0])\nindx = ms.train_test_split(indx, test_size = 80)\nX_train = Features[indx[0],:]\ny_train = np.ravel(Labels[indx[0]])\nX_test = Features[indx[1],:]\ny_test = np.ravel(Labels[indx[1]])",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nr.seed(1115)\nrf_mod = RandomForestClassifier(class_weight = {0:0.85, 1:0.15}, \n                                n_estimators = 100,\n                                max_features = rf_clf.best_estimator_.max_features, \n                                min_samples_leaf = rf_clf.best_estimator_.min_samples_leaf) \nrf_mod.fit(X_train, y_train)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=True, class_weight={0: 0.85, 1: 0.15},\n            criterion='gini', max_depth=None, max_features=2,\n            max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=3,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            n_estimators=100, n_jobs=None, oob_score=False,\n            random_state=None, verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def score_model(probs, threshold):\n    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n\ndef print_metrics(labels, probs, threshold):\n    scores = score_model(probs, threshold)\n    metrics = sklm.precision_recall_fscore_support(labels, scores)\n    conf = sklm.confusion_matrix(labels, scores)\n    print('                 Confusion matrix')\n    print('                 Score positive    Score negative')\n    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n    print('')\n    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n    print(' ')\n    print('           Positive      Negative')\n    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n    \nprobabilities = rf_mod.predict_proba(X_test)\nprint_metrics(y_test, probabilities, 0.5)     ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                 Confusion matrix\n                 Score positive    Score negative\nActual positive        29                 4\nActual negative        18                29\n\nAccuracy        0.72\nAUC             0.90\nMacro precision 0.75\nMacro recall    0.75\n \n           Positive      Negative\nNum case       33            47\nPrecision    0.62          0.88\nRecall       0.88          0.62\nF1           0.73          0.73\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "This particular model is worse than in regression created in previous notebook. It is possible that author is not competetive enough to find and use proper parameters to maximaze the performance."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}